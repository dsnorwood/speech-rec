{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Sampled Data\n",
    "\n",
    "This notebook will show how to process the \"left-side\" and \"right-side\" wav files. \n",
    "\n",
    "Specifically, I will take each one minute clip and build 120 rows (one second each) of a dataset.\n",
    "\n",
    "This could be further processed, structured, etc. based on the features extracted for a neural network. \n",
    "\n",
    "I thought this was a good link for normalizing your data: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import wave\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import vstack\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale # this one accepts 1D arrays\n",
    "import scipy.stats as sp\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWav(audio_wav):\n",
    "    #upload .wav files (sampled from Windows side and copied over to guest side)\n",
    "    rate, sampleWav0    = read(audio_wav)\n",
    "\n",
    "    # gets one channel from the wav file input\n",
    "    sample                                      = np.array(sampleWav0)\n",
    "\n",
    "    dim = len(sample.shape)\n",
    "    if dim >= 2:\n",
    "        sampleWav = sampleWav0[:,1]\n",
    "        sample = sample[:,1]\n",
    "    else:\n",
    "        sampleWav = sampleWav0\n",
    "\n",
    "    return sample, sampleWav, rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitWav(data, num_pieces):\n",
    "    print(\"ORIGINAL SHAPE:\", data.shape)\n",
    "    a = data.reshape(num_pieces, int(len(data) / num_pieces))\n",
    "    print(\"NEW SHAPE:\", a.shape)\n",
    "    return a\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not the most familiar with MFCC and librosa, so at the moment I'm taking this piece for granted. \n",
    "# I'll question what exactly it does later, but on the surface it supposedly takes a time-domain waveform and \n",
    "# returns the MFFC coefficients.\n",
    "#\n",
    "# In this case, each one second sample (10000 samples) returns a 13x20 MFFC matrix\n",
    "# I split one minute of sampling into 60 pieces, so I have 60 13x20 MFFC cofficients for each sampled \"event\"\n",
    "#\n",
    "# Generate mfccs from a time series\n",
    "\n",
    "def getMFCC(data, rate, num_pieces):    \n",
    "    mfcc = librosa.feature.mfcc(y=data[0], sr=rate, n_mfcc=13)\n",
    "    mfcc = np.expand_dims(mfcc, axis=0)\n",
    "    for i in range(1, num_pieces):\n",
    "        result = librosa.feature.mfcc(y=data[i], sr=rate, n_mfcc=13)\n",
    "        result = np.expand_dims(result, axis=0)\n",
    "        mfcc = vstack((mfcc,result))    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(left_d, right_d):\n",
    "    # Subplots\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "    axs[1].plot(left_d)\n",
    "    axs[0].plot(right_d)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def main():\n",
    "    # two wav files.\n",
    "    # left-side: me tapping on the left side of my computer for one minute\n",
    "    # right-side: me tapping on the right side of my computer\n",
    "    left_filename               = 'left-side.wav' #args.train_file    # get recorded wave\n",
    "    right_filename              = 'right-side.wav' #args.predict_file\n",
    "\n",
    "    # converting wav to numpy\n",
    "    left_all, leftWav, rate     = getWav(left_filename)\n",
    "    right_all, rightWav, rate   = getWav(right_filename)\n",
    "        \n",
    "    # normalize data\n",
    "    left_scaled                 = minmax_scale(left_all)\n",
    "    right_scaled                = minmax_scale(right_all)\n",
    "    \n",
    "    # reshape 1D array in MxN\n",
    "    # I basically want to split my one minute of data into 60 one-second clips\n",
    "    left_data                   = splitWav(left_scaled,60)\n",
    "    right_data                  = splitWav(right_scaled,60)\n",
    "\n",
    "    # MFCC features. I may have to explore this again later\n",
    "    left_mfcc                   = getMFCC(left_data, rate, 60)\n",
    "    right_mfcc                  = getMFCC(right_data, rate, 60)\n",
    "       \n",
    "    print(\"Final MFCC Shape:\", left_mfcc.shape) # I want 60, MFCC matrices\n",
    "    \n",
    "    \n",
    "    # --- LOOKING AT THINGS ---    \n",
    "    #  maybe this isn't the best way to visualize differences ...\n",
    "    #  but, I know I'll get 1 diagonally, but will get different values elsewhere\n",
    "    #  I guess I'm thinking if the two mffc matrixs are different, I can \"see\" it this way\n",
    "    #  If they are the same, or close, the graphs will be similar\n",
    "    #  What I'm looking at clearly (visually) says \"these are different\"\n",
    "    #  Since the two \"look\" different, I will go forward with using these MFCC matrices as features for a CNN\n",
    "    #left_features               = pd.DataFrame(data=left_mfcc[0])\n",
    "    #right_features              = pd.DataFrame(data=right_mfcc[0])\n",
    "    #plt.matshow(left_features.corr())\n",
    "    #plt.show()\n",
    "    #plt.matshow(right_features.corr())\n",
    "    #plt.show()\n",
    "    #plotData(left_data[0], right_data[0])\n",
    "    \n",
    "    \n",
    "    # TODO:\n",
    "    # Label each feature set\n",
    "    # Combine feature sets into one\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
